{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "748394da8a867656525da93a356544f0f15fb0021d7a843e967cb2c6876245f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed 고정\n",
    "random_seed=1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.random.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 종류\n(89355, 24)\nIndex(['신고번호', '신고일자', '통관지세관부호', '신고인부호', '수입자부호', '해외거래처부호', '특송업체부호',\n       '수입통관계획코드', '수입신고구분코드', '수입거래구분코드', '수입종류코드', '징수형태코드', '신고중량(KG)',\n       '과세가격원화금액', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호', '적출국가코드', '원산지국가코드',\n       '관세율구분코드', '관세율', '검사결과코드', '우범여부', '핵심적발'],\n      dtype='object')\n제거 후 데이터 종류 Index(['통관지세관부호', '신고인부호', '특송업체부호', '수입통관계획코드', '수입신고구분코드', '수입거래구분코드',\n       '수입종류코드', '징수형태코드', '운송수단유형코드', '반입보세구역부호', '적출국가코드', '원산지국가코드',\n       '관세율구분코드'],\n      dtype='object')\n       통관지세관부호  신고인부호   특송업체부호 수입통관계획코드 수입신고구분코드  수입거래구분코드  수입종류코드  징수형태코드  \\\n89350       10  M9SYU   PR5UFJ        C        B        11      21      11   \n89351       41  T7VQN  missing        E        E        15      11      11   \n89352       40  7Q31W  missing        C        B        29      21      11   \n89353       40  UJ0JR   O04TIW        F        B        15      21      14   \n89354       30  4TUUB  missing        Z        B        15      21      11   \n\n       운송수단유형코드  반입보세구역부호 적출국가코드 원산지국가코드 관세율구분코드  \n89350        10   4002001     CN      CN      W2  \n89351        40   4077008     CN      CN    FCN1  \n89352        10   2086001     CN      CN       A  \n89353        40   1618003     CA      CA       C  \n89354        10   3078039     HK      HK       C  \n"
     ]
    }
   ],
   "source": [
    "train_origin_data=pd.read_csv('./data/custom_contest/train.csv')\n",
    "test_origin_data=pd.read_csv('./data/custom_contest/test.csv')\n",
    "'''\n",
    "0은 바꿀 필요가 있음 o는 숫자이므로 유지\n",
    "신고번호 = x\n",
    "신고일자 = x\n",
    "통관지세관부호 = o\n",
    "신고인부호 = 0\n",
    "수입자부호 = 0\n",
    "해외 거래처 부호 = 0\n",
    "특송업체부호 = 0 \n",
    "\n",
    "'''\n",
    "train_origin_data=train_origin_data.fillna('missing')\n",
    "# 데이터 확인\n",
    "print('Data 종류')\n",
    "print(train_origin_data.shape)\n",
    "print(train_origin_data.columns)\n",
    "# 쓸모없는 데이터 날리기\n",
    "train_origin_data.drop('신고번호',axis=1,inplace=True)\n",
    "train_origin_data.drop('신고일자',axis=1,inplace=True)\n",
    "train_origin_data.drop('수입자부호',axis=1,inplace=True)\n",
    "train_origin_data.drop('검사결과코드',axis=1,inplace=True)\n",
    "train_origin_data.drop('해외거래처부호',axis=1,inplace=True)\n",
    "train_origin_data.drop('HS10단위부호',axis=1,inplace=True)\n",
    "# target 두개 분리\n",
    "crime_target=torch.tensor(train_origin_data.pop('우범여부').to_numpy())#,dtype=torch.float)\n",
    "priority_target=torch.tensor(train_origin_data.pop('핵심적발').to_numpy())\n",
    "#numerical data 분리\n",
    "train_weight=np.log(train_origin_data.pop('신고중량(KG)').to_numpy()+1).reshape(-1,1)\n",
    "train_price=np.log(train_origin_data.pop('과세가격원화금액').to_numpy()+1).reshape(-1,1)\n",
    "train_custom_rate=train_origin_data.pop('관세율').to_numpy().reshape(-1,1)\n",
    "# 분리 확인\n",
    "print('제거 후 데이터 종류',train_origin_data.columns)\n",
    "print(train_origin_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "통관지세관부호 : (89355, 40)\n",
      "신고인부호 : (89355, 965)\n",
      "특송업체부호 : (89355, 81)\n",
      "수입통관계획코드 : (89355, 7)\n",
      "수입신고구분코드 : (89355, 4)\n",
      "수입거래구분코드 : (89355, 25)\n",
      "수입종류코드 : (89355, 10)\n",
      "징수형태코드 : (89355, 9)\n",
      "운송수단유형코드 : (89355, 6)\n",
      "반입보세구역부호 : (89355, 568)\n",
      "적출국가코드 : (89355, 89)\n",
      "원산지국가코드 : (89355, 94)\n",
      "관세율구분코드 : (89355, 35)\n"
     ]
    }
   ],
   "source": [
    "for key in train_origin_data.keys():\n",
    "    enc=OneHotEncoder().fit(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "    encoded_data=enc.transform(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "    print(key,':',encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "encoded dataset (89355, 1933)\n",
      "torch.Size([89355, 1936])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# One hot encoding\n",
    "enc=OneHotEncoder(dtype=np.float32).fit(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns)))\n",
    "train_encoded_data=enc.transform(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns))).toarray()\n",
    "print(\"encoded dataset\",train_encoded_data.shape)\n",
    "\n",
    "# concat dataset\n",
    "train_price_tensor=torch.tensor(train_price,dtype=torch.float)\n",
    "train_weight_tensor=torch.tensor(train_weight,dtype=torch.float)\n",
    "train_custom_rate_tensor=torch.tensor(train_custom_rate,dtype=torch.float)\n",
    "train_encoded_data_tensor=torch.tensor(train_encoded_data,dtype=torch.float)\n",
    "train_tensor_data=torch.cat((train_encoded_data_tensor,train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "# train_tensor_data=torch.cat((train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "del train_price,train_weight,train_custom_rate,train_encoded_data\n",
    "print(train_tensor_data.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data 자르기\n",
    "batch_size=128\n",
    "test_split_rate=0.2\n",
    "indices=np.arange(len(train_tensor_data))\n",
    "dataset=TensorDataset(train_tensor_data,crime_target)\n",
    "# x,y train_index,test_index 보내기\n",
    "# model 구조\n",
    "train_indices,test_indices=train_test_split(indices,stratify=crime_target)\n",
    "np.save('./data/custom_contest/mod_data.npy',train_tensor_data.numpy())\n",
    "np.save('./data/custom_contest/mod_crime_target.npy',crime_target)\n",
    "np.save('./data/custom_contest/mod_priority_target.npy',priority_target)\n",
    "np.save('./data/custom_contest/mod_train_index.npy',train_indices)\n",
    "np.save('./data/custom_contest/mod_test_index.npy',test_indices)\n",
    "train_dataset=Subset(dataset,train_indices)\n",
    "test_dataset=Subset(dataset,test_indices)\n",
    "train_data_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True,)\n",
    "test_data_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=nn.Sequential(nn.Linear(train_tensor_data.shape[1],5000),\n",
    "    nn.BatchNorm1d(5000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5000,1000),\n",
    "    nn.BatchNorm1d(1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000,100),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,2),\n",
    "    # nn.Sigmoid()\n",
    "    )\n",
    "# criterion=torch.nn.BCELoss()\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "epochs=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1epoch 64256/67016, Accurcay: 79.30 Loss:0.44348\n",
      " Eval: 1 epoch, Accuracy: 79.01, Loss: 0.4317009210700297\n",
      "2epoch 6656/67016, Accurcay: 80.06 Loss:0.42172"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e2ca44b1bb7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m   \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e2ca44b1bb7d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, train_data_loader, model)\u001b[0m\n\u001b[0;32m     15\u001b[0m       \u001b[0mcorrect\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m       \u001b[0mtrain_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m           \u001b[1;31m# print(outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch,train_data_loader,model):\n",
    "  model.train()\n",
    "  total=0\n",
    "  correct=0.0\n",
    "  train_loss=0.0\n",
    "  for batch_idx, (data,targets) in enumerate(train_data_loader):\n",
    "      data,targets=data.cuda(),targets.cuda()\n",
    "      outputs=model(data)\n",
    "      loss=criterion(outputs,targets)#.view(-1,1))\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # correct+=torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).sum()\n",
    "      correct+=torch.eq(torch.max(outputs,dim=1)[1],targets).sum()\n",
    "      total += targets.size(0)\n",
    "      train_loss+=loss.item()\n",
    "      if batch_idx%50==1:\n",
    "          # print(outputs)\n",
    "          # print(torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).view(-1))\n",
    "          print('\\r{}epoch {}/{}, Accurcay: {:.2f} Loss:{:.5f}'.format(epoch,total,len(train_data_loader.dataset),correct/total*100.0,train_loss/(batch_idx+1)),end='')\n",
    "\n",
    "def eval(epoch,test_data_loader,model):\n",
    "    model.eval()\n",
    "    eval_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0.0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx,(data,targets) in enumerate(test_data_loader):\n",
    "          data,targets=data.cuda(),targets.cuda()\n",
    "          outputs=model(data)\n",
    "          loss=criterion(outputs,targets)#.view(-1,1))\n",
    "          # correct+=torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).sum()\n",
    "          correct+=torch.eq(torch.max(outputs,dim=1)[1],targets).sum()\n",
    "          total += targets.size(0)\n",
    "          eval_loss +=loss.item()\n",
    "\n",
    "    print('\\n Eval: {} epoch, Accuracy: {:.2f}, Loss: {}'.format(epoch,correct/total*100.0,eval_loss/(batch_idx+1)))\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "for epoch in range(1,epochs+1):\n",
    "  train(epoch,train_data_loader,model)\n",
    "  eval(epoch,test_data_loader,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}