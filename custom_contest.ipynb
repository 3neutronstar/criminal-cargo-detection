{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "748394da8a867656525da93a356544f0f15fb0021d7a843e967cb2c6876245f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed 고정\n",
    "random_seed=1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.random.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 종류\n",
      "(89355, 24)\n",
      "Index(['신고번호', '신고일자', '통관지세관부호', '신고인부호', '수입자부호', '해외거래처부호', '특송업체부호',\n",
      "       '수입통관계획코드', '수입신고구분코드', '수입거래구분코드', '수입종류코드', '징수형태코드', '신고중량(KG)',\n",
      "       '과세가격원화금액', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호', '적출국가코드', '원산지국가코드',\n",
      "       '관세율구분코드', '관세율', '검사결과코드', '우범여부', '핵심적발'],\n",
      "      dtype='object')\n",
      "제거 후 데이터 종류 Index(['통관지세관부호', '신고인부호', '해외거래처부호', '특송업체부호', '수입통관계획코드', '수입신고구분코드',\n",
      "       '수입거래구분코드', '수입종류코드', '징수형태코드', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호',\n",
      "       '적출국가코드', '원산지국가코드', '관세율구분코드', '특송부호', '수입자부호', '해외업체부호'],\n",
      "      dtype='object')\n",
      "       통관지세관부호    신고인부호  해외거래처부호   특송업체부호 수입통관계획코드 수입신고구분코드  수입거래구분코드  수입종류코드  \\\n",
      "89350       10  Missing  missing   PR5UFJ        C        B        11      21   \n",
      "89351       41  Missing  missing  missing        E        E        15      11   \n",
      "89352       40    7Q31W  QW3LA8B  missing        C        B        29      21   \n",
      "89353       40  Missing  TJW57CJ   O04TIW        F        B        15      21   \n",
      "89354       30  Missing  0UOB77D  missing        Z        B        15      21   \n",
      "\n",
      "       징수형태코드  운송수단유형코드  반입보세구역부호    HS10단위부호 적출국가코드 원산지국가코드 관세율구분코드     특송부호  \\\n",
      "89350      11        10   4002001   703101000     CN      CN      W2   PR5UFJ   \n",
      "89351      11        40   4077008  6804220000     CN      CN    FCN1  Missing   \n",
      "89352      11        10   2086001  8210005000     CN      CN       A  Missing   \n",
      "89353      14        40   1618003  3304999000     CA      CA       C  Missing   \n",
      "89354      11        10   3078039  3304999000     HK      HK       C  Missing   \n",
      "\n",
      "         수입자부호   해외업체부호  \n",
      "89350  Missing  Missing  \n",
      "89351  Missing  Missing  \n",
      "89352  Missing  Missing  \n",
      "89353  Missing  Missing  \n",
      "89354  Missing  Missing  \n",
      "통관지세관부호 : (89355, 40)\n",
      "신고인부호 : (89355, 41)\n",
      "해외거래처부호 : (89355, 4779)\n",
      "특송업체부호 : (89355, 81)\n",
      "수입통관계획코드 : (89355, 7)\n",
      "수입신고구분코드 : (89355, 4)\n",
      "수입거래구분코드 : (89355, 25)\n",
      "수입종류코드 : (89355, 10)\n",
      "징수형태코드 : (89355, 9)\n",
      "운송수단유형코드 : (89355, 6)\n",
      "반입보세구역부호 : (89355, 568)\n",
      "HS10단위부호 : (89355, 2419)\n",
      "적출국가코드 : (89355, 89)\n",
      "원산지국가코드 : (89355, 94)\n",
      "관세율구분코드 : (89355, 35)\n",
      "특송부호 : (89355, 5)\n",
      "수입자부호 : (89355, 101)\n",
      "해외업체부호 : (89355, 80)\n",
      "encoded dataset (89355, 8393)\n",
      "torch.Size([89355, 8396])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    train_origin_data=pd.read_csv('./data/custom_contest/train.csv')\n",
    "    '''\n",
    "    0은 바꿀 필요가 있음 o는 숫자이므로 유지\n",
    "    신고번호 = x\n",
    "    신고일자 = x\n",
    "    통관지세관부호 = o\n",
    "    신고인부호 = 0\n",
    "    수입자부호 = 0\n",
    "    해외 거래처 부호 = 0\n",
    "    특송업체부호 = 0 \n",
    "\n",
    "    '''\n",
    "    train_origin_data=train_origin_data.fillna('missing')\n",
    "    # 데이터 확인\n",
    "    print('Data 종류')\n",
    "    print(train_origin_data.shape)\n",
    "    print(train_origin_data.columns)\n",
    "    # 쓸모없는 데이터 날리기\n",
    "    train_origin_data.drop('신고번호',axis=1,inplace=True)\n",
    "    train_origin_data.drop('신고일자',axis=1,inplace=True)\n",
    "    train_origin_data.drop('수입자부호',axis=1,inplace=True)\n",
    "    train_origin_data.drop('검사결과코드',axis=1,inplace=True)\n",
    "    # train_origin_data.drop('해외거래처부호',axis=1,inplace=True)\n",
    "    # train_origin_data.drop('HS10단위부호',axis=1,inplace=True)\n",
    "\n",
    "    # target 두개 분리\n",
    "    crime_target=torch.tensor(train_origin_data.pop('우범여부').to_numpy())#,dtype=torch.float)\n",
    "    priority_target=torch.tensor(train_origin_data.pop('핵심적발').to_numpy())\n",
    "    #numerical data 분리\n",
    "    train_weight=np.log(train_origin_data.pop('신고중량(KG)').to_numpy()+1).reshape(-1,1)\n",
    "    train_price=np.log(train_origin_data.pop('과세가격원화금액').to_numpy()+1).reshape(-1,1)\n",
    "    train_custom_rate=train_origin_data.pop('관세율').to_numpy().reshape(-1,1)\n",
    "\n",
    "    #replace data\n",
    "    train_submit=np.load('./data/custom_contest/submit.npy',allow_pickle=True)\n",
    "    train_express=np.load('./data/custom_contest/express.npy',allow_pickle=True)\n",
    "    train_import=np.load('./data/custom_contest/import.npy',allow_pickle=True)\n",
    "    train_company=np.load('./data/custom_contest/company.npy',allow_pickle=True)\n",
    "    train_origin_data['신고인부호']=train_submit\n",
    "    train_origin_data['특송부호']=train_express\n",
    "    train_origin_data['수입자부호']=train_import\n",
    "    train_origin_data['해외업체부호']=train_company\n",
    "    # 분리 확인\n",
    "    print('제거 후 데이터 종류',train_origin_data.columns)\n",
    "    print(train_origin_data.tail())\n",
    "\n",
    "    for key in train_origin_data.keys():\n",
    "        enc=OneHotEncoder().fit(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "        encoded_data=enc.transform(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "        print(key,':',encoded_data.shape)\n",
    "\n",
    "    # One hot encoding\n",
    "    enc=OneHotEncoder(dtype=np.float32).fit(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns)))\n",
    "    train_encoded_data=enc.transform(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns))).toarray()\n",
    "    print(\"encoded dataset\",train_encoded_data.shape)\n",
    "\n",
    "    # numerical dataset\n",
    "    train_price_tensor=torch.tensor(train_price,dtype=torch.float)\n",
    "    train_weight_tensor=torch.tensor(train_weight,dtype=torch.float)\n",
    "    train_custom_rate_tensor=torch.tensor(train_custom_rate,dtype=torch.float)\n",
    "    # categorical dataset -> encoded data\n",
    "    train_encoded_data_tensor=torch.tensor(train_encoded_data,dtype=torch.float)\n",
    "    train_tensor_data=torch.cat((train_encoded_data_tensor,train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "\n",
    "\n",
    "    indices=np.arange(len(train_tensor_data))\n",
    "    # train_tensor_data=torch.cat((train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "    del train_price,train_weight,train_custom_rate,train_encoded_data\n",
    "    print(train_tensor_data.size())\n",
    "    train_indices,test_indices=train_test_split(indices,stratify=crime_target)\n",
    "\n",
    "    np.save('./data/custom_contest/mod_data.npy',train_tensor_data.numpy())\n",
    "    np.save('./data/custom_contest/mod_crime_target.npy',crime_target)\n",
    "    np.save('./data/custom_contest/mod_priority_target.npy',priority_target)\n",
    "    np.save('./data/custom_contest/mod_train_index.npy',train_indices)\n",
    "    np.save('./data/custom_contest/mod_test_index.npy',test_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 종류\n(89355, 24)\nIndex(['신고번호', '신고일자', '통관지세관부호', '신고인부호', '수입자부호', '해외거래처부호', '특송업체부호',\n       '수입통관계획코드', '수입신고구분코드', '수입거래구분코드', '수입종류코드', '징수형태코드', '신고중량(KG)',\n       '과세가격원화금액', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호', '적출국가코드', '원산지국가코드',\n       '관세율구분코드', '관세율', '검사결과코드', '우범여부', '핵심적발'],\n      dtype='object')\n제거 후 데이터 종류\n Index(['통관지세관부호', '신고인부호', '특송업체부호', '수입통관계획코드', '수입신고구분코드', '수입거래구분코드',\n       '수입종류코드', '징수형태코드', '운송수단유형코드', '반입보세구역부호', '적출국가코드', '원산지국가코드',\n       '관세율구분코드'],\n      dtype='object')\n       통관지세관부호  신고인부호   특송업체부호 수입통관계획코드 수입신고구분코드  수입거래구분코드  수입종류코드  징수형태코드  \\\n89350       10  M9SYU   PR5UFJ        C        B        11      21      11   \n89351       41  T7VQN  missing        E        E        15      11      11   \n89352       40  7Q31W  missing        C        B        29      21      11   \n89353       40  UJ0JR   O04TIW        F        B        15      21      14   \n89354       30  4TUUB  missing        Z        B        15      21      11   \n\n       운송수단유형코드  반입보세구역부호 적출국가코드 원산지국가코드 관세율구분코드  \n89350        10   4002001     CN      CN      W2  \n89351        40   4077008     CN      CN    FCN1  \n89352        10   2086001     CN      CN       A  \n89353        40   1618003     CA      CA       C  \n89354        10   3078039     HK      HK       C  \n"
     ]
    }
   ],
   "source": [
    "train_origin_data=pd.read_csv('./data/custom_contest/train.csv')\n",
    "test_origin_data=pd.read_csv('./data/custom_contest/test.csv')\n",
    "'''\n",
    "0은 바꿀 필요가 있음 o는 숫자이므로 유지\n",
    "신고번호 = x\n",
    "신고일자 = x\n",
    "통관지세관부호 = o\n",
    "신고인부호 = 0\n",
    "수입자부호 = 0\n",
    "해외 거래처 부호 = 0\n",
    "특송업체부호 = 0 \n",
    "'''\n",
    "\n",
    "train_origin_data=train_origin_data.fillna('missing')\n",
    "\n",
    "# 데이터 확인\n",
    "print('Data 종류')\n",
    "print(train_origin_data.shape)\n",
    "print(train_origin_data.columns)\n",
    "# 쓸모없는 데이터 날리기\n",
    "train_origin_data.drop('신고번호',axis=1,inplace=True)\n",
    "train_origin_data.drop('신고일자',axis=1,inplace=True)\n",
    "train_origin_data.drop('수입자부호',axis=1,inplace=True)\n",
    "# train_origin_data.drop('특송업체부호',axis=1,inplace=True)\n",
    "train_origin_data.drop('검사결과코드',axis=1,inplace=True)\n",
    "train_origin_data.drop('해외거래처부호',axis=1,inplace=True)\n",
    "train_origin_data.drop('HS10단위부호',axis=1,inplace=True)\n",
    "# target 두개 분리\n",
    "crime_target=torch.tensor(train_origin_data.pop('우범여부').to_numpy())#,dtype=torch.float)\n",
    "priority_target=torch.tensor(train_origin_data.pop('핵심적발').to_numpy())\n",
    "#numerical data 분리\n",
    "epsilon=1e-7\n",
    "scaler=MinMaxScaler()\n",
    "train_weight=scaler.fit_transform(np.log(train_origin_data.pop('신고중량(KG)').to_numpy()+epsilon).reshape(-1,1))\n",
    "train_price=scaler.fit_transform(np.log(train_origin_data.pop('과세가격원화금액').to_numpy()+epsilon).reshape(-1,1))\n",
    "train_custom_rate=scaler.fit_transform(train_origin_data.pop('관세율').to_numpy().reshape(-1,1))\n",
    "# 분리 확인\n",
    "print('제거 후 데이터 종류\\n',train_origin_data.columns)\n",
    "print(train_origin_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "통관지세관부호 : (89355, 40)\n신고인부호 : (89355, 965)\n특송업체부호 : (89355, 81)\n수입통관계획코드 : (89355, 7)\n수입신고구분코드 : (89355, 4)\n수입거래구분코드 : (89355, 25)\n수입종류코드 : (89355, 10)\n징수형태코드 : (89355, 9)\n운송수단유형코드 : (89355, 6)\n반입보세구역부호 : (89355, 568)\n적출국가코드 : (89355, 89)\n원산지국가코드 : (89355, 94)\n관세율구분코드 : (89355, 35)\n"
     ]
    }
   ],
   "source": [
    "for key in train_origin_data.keys():\n",
    "    enc=OneHotEncoder().fit(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "    encoded_data=enc.transform(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "    print(key,':',encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "encoded dataset (89355, 1933)\n",
      "torch.Size([89355, 1936])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# One hot encoding\n",
    "enc=OneHotEncoder(dtype=np.float32).fit(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns)))\n",
    "train_encoded_data=enc.transform(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns))).toarray()\n",
    "print(\"encoded dataset\",train_encoded_data.shape)\n",
    "\n",
    "# concat dataset\n",
    "train_price_tensor=torch.tensor(train_price,dtype=torch.float)\n",
    "train_weight_tensor=torch.tensor(train_weight,dtype=torch.float)\n",
    "train_custom_rate_tensor=torch.tensor(train_custom_rate,dtype=torch.float)\n",
    "train_encoded_data_tensor=torch.tensor(train_encoded_data,dtype=torch.float)\n",
    "train_tensor_data=torch.cat((train_encoded_data_tensor,train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "# train_tensor_data=torch.cat((train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "del train_price,train_weight,train_custom_rate,train_encoded_data\n",
    "print(train_tensor_data.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data 자르기\n",
    "batch_size=128\n",
    "test_split_rate=0.2\n",
    "indices=np.arange(len(train_tensor_data))\n",
    "crime_dataset=TensorDataset(train_tensor_data,crime_target)\n",
    "priority_dataset=TensorDataset(train_tensor_data,priority_target.float())\n",
    "# x,y train_index,test_index 보내기\n",
    "# model 구조\n",
    "train_indices,test_indices=train_test_split(indices,stratify=crime_target)\n",
    "np.save('./data/custom_contest/mod_data.npy',train_tensor_data.numpy())\n",
    "np.save('./data/custom_contest/mod_crime_target.npy',crime_target)\n",
    "np.save('./data/custom_contest/mod_priority_target.npy',priority_target)\n",
    "np.save('./data/custom_contest/mod_train_index.npy',train_indices)\n",
    "np.save('./data/custom_contest/mod_test_index.npy',test_indices)\n",
    "#crime\n",
    "crime_train_dataset=Subset(crime_dataset,train_indices)\n",
    "crime_test_dataset=Subset(crime_dataset,test_indices)\n",
    "crime_train_data_loader=DataLoader(crime_train_dataset,batch_size=batch_size,shuffle=True)\n",
    "crime_test_data_loader=DataLoader(crime_test_dataset,batch_size=batch_size,shuffle=False)\n",
    "#priority\n",
    "priority_train_dataset=Subset(priority_dataset,train_indices)\n",
    "priority_test_dataset=Subset(priority_dataset,test_indices)\n",
    "priority_train_data_loader=DataLoader(priority_train_dataset,batch_size=batch_size,shuffle=True,)\n",
    "priority_test_data_loader=DataLoader(priority_test_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " [precision] 59.40 [recall] 31.91 [f1score] 41.51\n",
      "15epoch 64256/67016, [Acc] 79.67 [Loss] 0.43338\n",
      "[15epoch Train] [loss] 0.43449 [acc] 79.60 [precision] 60.74 [recall] 32.09 [f1score] 42.00\n",
      "\n",
      "[15epoch Test] [loss] 0.44116 [acc] 79.35 [precision] 60.88 [recall] 28.74 [f1score] 39.04\n",
      "16epoch 64256/67016, [Acc] 79.54 [Loss] 0.43448\n",
      "[16epoch Train] [loss] 0.43495 [acc] 79.52 [precision] 60.29 [recall] 32.23 [f1score] 42.00\n",
      "\n",
      "[16epoch Test] [loss] 0.44060 [acc] 79.14 [precision] 62.13 [recall] 23.91 [f1score] 34.53\n",
      "17epoch 64256/67016, [Acc] 79.58 [Loss] 0.43385\n",
      "[17epoch Train] [loss] 0.43480 [acc] 79.51 [precision] 60.43 [recall] 31.74 [f1score] 41.62\n",
      "\n",
      "[17epoch Test] [loss] 0.44196 [acc] 79.28 [precision] 59.77 [recall] 30.41 [f1score] 40.31\n",
      "18epoch 64256/67016, [Acc] 79.72 [Loss] 0.43427\n",
      "[18epoch Train] [loss] 0.43432 [acc] 79.72 [precision] 61.34 [recall] 32.14 [f1score] 42.18\n",
      "\n",
      "[18epoch Test] [loss] 0.44060 [acc] 79.18 [precision] 59.89 [recall] 28.85 [f1score] 38.94\n",
      "19epoch 64256/67016, [Acc] 79.56 [Loss] 0.43477\n",
      "[19epoch Train] [loss] 0.43458 [acc] 79.56 [precision] 60.52 [recall] 32.17 [f1score] 42.01\n",
      "\n",
      "[19epoch Test] [loss] 0.44020 [acc] 79.31 [precision] 59.81 [recall] 30.66 [f1score] 40.54\n",
      "20epoch 64256/67016, [Acc] 79.57 [Loss] 0.43513\n",
      "[20epoch Train] [loss] 0.43480 [acc] 79.56 [precision] 60.91 [recall] 31.15 [f1score] 41.22\n",
      "\n",
      "[20epoch Test] [loss] 0.44042 [acc] 79.26 [precision] 60.98 [recall] 27.45 [f1score] 37.86\n",
      "21epoch 64256/67016, [Acc] 79.54 [Loss] 0.43470\n",
      "[21epoch Train] [loss] 0.43476 [acc] 79.58 [precision] 60.93 [recall] 31.32 [f1score] 41.37\n",
      "\n",
      "[21epoch Test] [loss] 0.44128 [acc] 79.08 [precision] 63.49 [recall] 21.38 [f1score] 31.99\n",
      "22epoch 64256/67016, [Acc] 79.67 [Loss] 0.43390\n",
      "[22epoch Train] [loss] 0.43425 [acc] 79.64 [precision] 61.22 [recall] 31.41 [f1score] 41.52\n",
      "\n",
      "[22epoch Test] [loss] 0.44534 [acc] 79.25 [precision] 59.30 [recall] 31.26 [f1score] 40.94\n",
      "23epoch 64256/67016, [Acc] 79.54 [Loss] 0.43498\n",
      "[23epoch Train] [loss] 0.43529 [acc] 79.55 [precision] 61.05 [recall] 30.69 [f1score] 40.85\n",
      "\n",
      "[23epoch Test] [loss] 0.44395 [acc] 79.01 [precision] 57.54 [recall] 33.40 [f1score] 42.27\n",
      "24epoch 64256/67016, [Acc] 79.46 [Loss] 0.43512\n",
      "[24epoch Train] [loss] 0.43555 [acc] 79.44 [precision] 60.66 [recall] 30.34 [f1score] 40.45\n",
      "\n",
      "[24epoch Test] [loss] 0.44257 [acc] 79.04 [precision] 64.08 [recall] 20.27 [f1score] 30.80\n",
      "25epoch 64256/67016, [Acc] 79.49 [Loss] 0.43548\n",
      "[25epoch Train] [loss] 0.43515 [acc] 79.53 [precision] 60.91 [recall] 30.88 [f1score] 40.98\n",
      "\n",
      "[25epoch Test] [loss] 0.44203 [acc] 79.21 [precision] 59.58 [recall] 30.00 [f1score] 39.91\n",
      "26epoch 64256/67016, [Acc] 79.57 [Loss] 0.43442\n",
      "[26epoch Train] [loss] 0.43487 [acc] 79.55 [precision] 60.46 [recall] 32.11 [f1score] 41.94\n",
      "\n",
      "[26epoch Test] [loss] 0.44324 [acc] 79.12 [precision] 59.88 [recall] 28.07 [f1score] 38.23\n",
      "27epoch 64256/67016, [Acc] 79.63 [Loss] 0.43483\n",
      "[27epoch Train] [loss] 0.43515 [acc] 79.62 [precision] 60.80 [recall] 32.15 [f1score] 42.06\n",
      "\n",
      "[27epoch Test] [loss] 0.44292 [acc] 78.78 [precision] 66.00 [recall] 16.05 [f1score] 25.82\n",
      "28epoch 64256/67016, [Acc] 79.59 [Loss] 0.43404\n",
      "[28epoch Train] [loss] 0.43453 [acc] 79.54 [precision] 60.78 [recall] 31.28 [f1score] 41.31\n",
      "\n",
      "[28epoch Test] [loss] 0.44331 [acc] 79.38 [precision] 61.99 [recall] 26.85 [f1score] 37.47\n",
      "29epoch 64256/67016, [Acc] 79.68 [Loss] 0.43424\n",
      "[29epoch Train] [loss] 0.43419 [acc] 79.66 [precision] 60.95 [recall] 32.30 [f1score] 42.22\n",
      "\n",
      "[29epoch Test] [loss] 0.44040 [acc] 79.23 [precision] 62.40 [recall] 24.47 [f1score] 35.16\n",
      "30epoch 64256/67016, [Acc] 79.56 [Loss] 0.43408\n",
      "[30epoch Train] [loss] 0.43471 [acc] 79.55 [precision] 60.02 [recall] 33.34 [f1score] 42.87\n",
      "\n",
      "[30epoch Test] [loss] 0.44061 [acc] 79.23 [precision] 61.10 [recall] 26.77 [f1score] 37.23\n",
      "31epoch 64256/67016, [Acc] 79.54 [Loss] 0.43405\n",
      "[31epoch Train] [loss] 0.43424 [acc] 79.56 [precision] 60.37 [recall] 32.44 [f1score] 42.21\n",
      "\n",
      "[31epoch Test] [loss] 0.44552 [acc] 78.92 [precision] 56.65 [recall] 35.78 [f1score] 43.86\n",
      "32epoch 64256/67016, [Acc] 79.68 [Loss] 0.43378\n",
      "[32epoch Train] [loss] 0.43390 [acc] 79.67 [precision] 60.58 [recall] 33.35 [f1score] 43.02\n",
      "\n",
      "[32epoch Test] [loss] 0.44477 [acc] 78.76 [precision] 54.94 [recall] 42.74 [f1score] 48.08\n",
      "33epoch 64256/67016, [Acc] 79.56 [Loss] 0.43418\n",
      "[33epoch Train] [loss] 0.43409 [acc] 79.58 [precision] 60.47 [recall] 32.49 [f1score] 42.27\n",
      "\n",
      "[33epoch Test] [loss] 0.44417 [acc] 79.08 [precision] 62.87 [recall] 22.20 [f1score] 32.81\n",
      "34epoch 64256/67016, [Acc] 79.54 [Loss] 0.43428\n",
      "[34epoch Train] [loss] 0.43428 [acc] 79.54 [precision] 60.39 [recall] 32.15 [f1score] 41.96\n",
      "\n",
      "[34epoch Test] [loss] 0.45229 [acc] 78.68 [precision] 59.02 [recall] 24.07 [f1score] 34.19\n",
      "35epoch 64256/67016, [Acc] 79.70 [Loss] 0.43515\n",
      "[35epoch Train] [loss] 0.43492 [acc] 79.66 [precision] 61.06 [recall] 32.00 [f1score] 41.99\n",
      "\n",
      "[35epoch Test] [loss] 0.44279 [acc] 79.37 [precision] 60.09 [recall] 30.82 [f1score] 40.74\n",
      "36epoch 64256/67016, [Acc] 79.60 [Loss] 0.43349\n",
      "[36epoch Train] [loss] 0.43474 [acc] 79.54 [precision] 60.65 [recall] 31.60 [f1score] 41.55\n",
      "\n",
      "[36epoch Test] [loss] 0.44093 [acc] 79.28 [precision] 59.50 [recall] 31.21 [f1score] 40.94\n",
      "37epoch 64256/67016, [Acc] 79.67 [Loss] 0.43391\n",
      "[37epoch Train] [loss] 0.43456 [acc] 79.65 [precision] 61.36 [recall] 31.18 [f1score] 41.35\n",
      "\n",
      "[37epoch Test] [loss] 0.44458 [acc] 79.01 [precision] 56.30 [recall] 39.28 [f1score] 46.28\n",
      "38epoch 64256/67016, [Acc] 79.58 [Loss] 0.43492\n",
      "[38epoch Train] [loss] 0.43479 [acc] 79.59 [precision] 60.65 [recall] 32.22 [f1score] 42.08\n",
      "\n",
      "[38epoch Test] [loss] 0.44207 [acc] 79.41 [precision] 61.99 [recall] 27.16 [f1score] 37.77\n",
      "39epoch 64256/67016, [Acc] 79.50 [Loss] 0.43553\n",
      "[39epoch Train] [loss] 0.43529 [acc] 79.54 [precision] 60.77 [recall] 31.23 [f1score] 41.25\n",
      "\n",
      "[39epoch Test] [loss] 0.44280 [acc] 79.25 [precision] 59.60 [recall] 30.49 [f1score] 40.34\n",
      "40epoch 64256/67016, [Acc] 79.66 [Loss] 0.43352\n",
      "[40epoch Train] [loss] 0.43402 [acc] 79.65 [precision] 60.98 [recall] 32.14 [f1score] 42.09\n",
      "\n",
      "[40epoch Test] [loss] 0.44918 [acc] 78.59 [precision] 54.52 [recall] 42.02 [f1score] 47.46\n",
      "41epoch 64256/67016, [Acc] 79.69 [Loss] 0.43485\n",
      "[41epoch Train] [loss] 0.43488 [acc] 79.67 [precision] 60.92 [recall] 32.53 [f1score] 42.41\n",
      "\n",
      "[41epoch Test] [loss] 0.43914 [acc] 79.39 [precision] 63.18 [recall] 25.04 [f1score] 35.86\n",
      "42epoch 64256/67016, [Acc] 79.65 [Loss] 0.43399\n",
      "[42epoch Train] [loss] 0.43392 [acc] 79.64 [precision] 60.62 [recall] 32.81 [f1score] 42.58\n",
      "\n",
      "[42epoch Test] [loss] 0.44493 [acc] 78.88 [precision] 55.23 [recall] 43.42 [f1score] 48.62\n",
      "43epoch 64256/67016, [Acc] 79.57 [Loss] 0.43475\n",
      "[43epoch Train] [loss] 0.43423 [acc] 79.60 [precision] 60.59 [recall] 32.40 [f1score] 42.22\n",
      "\n",
      "[43epoch Test] [loss] 0.44209 [acc] 79.12 [precision] 64.08 [recall] 21.07 [f1score] 31.71\n",
      "44epoch 64256/67016, [Acc] 79.64 [Loss] 0.43412\n",
      "[44epoch Train] [loss] 0.43422 [acc] 79.62 [precision] 60.90 [recall] 31.97 [f1score] 41.93\n",
      "\n",
      "[44epoch Test] [loss] 0.44139 [acc] 79.26 [precision] 61.09 [recall] 27.12 [f1score] 37.56\n",
      "45epoch 64256/67016, [Acc] 79.62 [Loss] 0.43436\n",
      "[45epoch Train] [loss] 0.43445 [acc] 79.64 [precision] 60.84 [recall] 32.30 [f1score] 42.19\n",
      "\n",
      "[45epoch Test] [loss] 0.44475 [acc] 79.08 [precision] 57.08 [recall] 36.56 [f1score] 44.57\n",
      "46epoch 64256/67016, [Acc] 79.65 [Loss] 0.43469\n",
      "[46epoch Train] [loss] 0.43425 [acc] 79.65 [precision] 60.80 [recall] 32.58 [f1score] 42.43\n",
      "\n",
      "[46epoch Test] [loss] 0.44214 [acc] 79.17 [precision] 57.59 [recall] 35.88 [f1score] 44.21\n",
      "47epoch 64256/67016, [Acc] 79.63 [Loss] 0.43439\n",
      "[47epoch Train] [loss] 0.43464 [acc] 79.61 [precision] 60.86 [recall] 31.95 [f1score] 41.90\n",
      "\n",
      "[47epoch Test] [loss] 0.45231 [acc] 78.11 [precision] 70.78 [recall] 8.25 [f1score] 14.78\n",
      "48epoch 64256/67016, [Acc] 79.50 [Loss] 0.43433\n",
      "[48epoch Train] [loss] 0.43506 [acc] 79.47 [precision] 60.76 [recall] 30.38 [f1score] 40.50\n",
      "\n",
      "[48epoch Test] [loss] 0.44600 [acc] 79.09 [precision] 56.80 [recall] 38.21 [f1score] 45.69\n",
      "49epoch 64256/67016, [Acc] 79.61 [Loss] 0.43483\n",
      "[49epoch Train] [loss] 0.43453 [acc] 79.57 [precision] 61.53 [recall] 29.86 [f1score] 40.21\n",
      "\n",
      "[49epoch Test] [loss] 0.43935 [acc] 79.36 [precision] 61.21 [recall] 28.15 [f1score] 38.57\n",
      "50epoch 64256/67016, [Acc] 79.71 [Loss] 0.43424\n",
      "[50epoch Train] [loss] 0.43420 [acc] 79.68 [precision] 61.70 [recall] 30.77 [f1score] 41.06\n",
      "\n",
      "[50epoch Test] [loss] 0.44025 [acc] 79.22 [precision] 62.51 [recall] 24.16 [f1score] 34.85\n",
      "51epoch 64256/67016, [Acc] 79.64 [Loss] 0.43505\n",
      "[51epoch Train] [loss] 0.43487 [acc] 79.66 [precision] 61.30 [recall] 31.49 [f1score] 41.61\n",
      "\n",
      "[51epoch Test] [loss] 0.45334 [acc] 78.88 [precision] 55.67 [recall] 40.19 [f1score] 46.68\n",
      "52epoch 64256/67016, [Acc] 79.60 [Loss] 0.43431\n",
      "[52epoch Train] [loss] 0.43518 [acc] 79.55 [precision] 61.00 [recall] 30.88 [f1score] 41.00\n",
      "\n",
      "[52epoch Test] [loss] 0.44183 [acc] 79.22 [precision] 60.06 [recall] 28.99 [f1score] 39.10\n",
      "53epoch 64256/67016, [Acc] 79.61 [Loss] 0.43434\n",
      "[53epoch Train] [loss] 0.43465 [acc] 79.63 [precision] 61.40 [recall] 30.92 [f1score] 41.13\n",
      "\n",
      "[53epoch Test] [loss] 0.44469 [acc] 78.66 [precision] 66.37 [recall] 14.71 [f1score] 24.08\n",
      "54epoch 64256/67016, [Acc] 79.54 [Loss] 0.43460\n",
      "[54epoch Train] [loss] 0.43411 [acc] 79.59 [precision] 60.98 [recall] 31.31 [f1score] 41.38\n",
      "\n",
      "[54epoch Test] [loss] 0.44030 [acc] 79.30 [precision] 59.46 [recall] 31.50 [f1score] 41.18\n",
      "55epoch 64256/67016, [Acc] 79.70 [Loss] 0.43352\n",
      "[55epoch Train] [loss] 0.43423 [acc] 79.68 [precision] 60.94 [recall] 32.48 [f1score] 42.38\n",
      "\n",
      "[55epoch Test] [loss] 0.44140 [acc] 79.30 [precision] 62.06 [recall] 25.84 [f1score] 36.48\n",
      "56epoch 64256/67016, [Acc] 79.68 [Loss] 0.43365\n",
      "[56epoch Train] [loss] 0.43436 [acc] 79.66 [precision] 61.04 [recall] 32.09 [f1score] 42.06\n",
      "\n",
      "[56epoch Test] [loss] 0.44245 [acc] 79.43 [precision] 62.13 [recall] 27.16 [f1score] 37.80\n",
      "57epoch 64256/67016, [Acc] 79.59 [Loss] 0.43367\n",
      "[57epoch Train] [loss] 0.43437 [acc] 79.57 [precision] 60.65 [recall] 31.94 [f1score] 41.84\n",
      "\n",
      "[57epoch Test] [loss] 0.45172 [acc] 78.62 [precision] 54.77 [recall] 40.58 [f1score] 46.62\n",
      "58epoch 64256/67016, [Acc] 79.60 [Loss] 0.43374\n",
      "[58epoch Train] [loss] 0.43410 [acc] 79.59 [precision] 60.86 [recall] 31.66 [f1score] 41.65\n",
      "\n",
      "[58epoch Test] [loss] 0.44099 [acc] 79.30 [precision] 61.68 [recall] 26.50 [f1score] 37.07\n",
      "59epoch 64256/67016, [Acc] 79.57 [Loss] 0.43412\n",
      "[59epoch Train] [loss] 0.43455 [acc] 79.60 [precision] 60.77 [recall] 32.02 [f1score] 41.94\n",
      "\n",
      "[59epoch Test] [loss] 0.44052 [acc] 79.39 [precision] 61.64 [recall] 27.57 [f1score] 38.10\n",
      "60epoch 64256/67016, [Acc] 79.58 [Loss] 0.43443\n",
      "[60epoch Train] [loss] 0.43486 [acc] 79.54 [precision] 60.82 [recall] 31.15 [f1score] 41.20\n",
      "\n",
      "[60epoch Test] [loss] 0.44282 [acc] 79.18 [precision] 61.37 [recall] 25.62 [f1score] 36.15\n",
      "61epoch 64256/67016, [Acc] 79.64 [Loss] 0.43358\n",
      "[61epoch Train] [loss] 0.43473 [acc] 79.57 [precision] 60.48 [recall] 32.29 [f1score] 42.10\n",
      "\n",
      "[61epoch Test] [loss] 0.44210 [acc] 78.98 [precision] 64.94 [recall] 18.77 [f1score] 29.13\n",
      "62epoch 64256/67016, [Acc] 79.63 [Loss] 0.43391\n",
      "[62epoch Train] [loss] 0.43416 [acc] 79.63 [precision] 61.47 [recall] 30.71 [f1score] 40.96\n",
      "\n",
      "[62epoch Test] [loss] 0.44043 [acc] 79.31 [precision] 60.19 [recall] 29.77 [f1score] 39.83\n",
      "63epoch 64256/67016, [Acc] 79.61 [Loss] 0.43420\n",
      "[63epoch Train] [loss] 0.43481 [acc] 79.61 [precision] 61.44 [recall] 30.54 [f1score] 40.80\n",
      "\n",
      "[63epoch Test] [loss] 0.44365 [acc] 79.02 [precision] 61.36 [recall] 23.85 [f1score] 34.35\n",
      "64epoch 64256/67016, [Acc] 79.72 [Loss] 0.43417\n",
      "[64epoch Train] [loss] 0.43487 [acc] 79.65 [precision] 60.98 [recall] 32.11 [f1score] 42.07\n",
      "\n",
      "[64epoch Test] [loss] 0.44180 [acc] 79.20 [precision] 62.76 [recall] 23.64 [f1score] 34.34\n",
      "65epoch 64256/67016, [Acc] 79.63 [Loss] 0.43428\n",
      "[65epoch Train] [loss] 0.43457 [acc] 79.60 [precision] 60.89 [recall] 31.69 [f1score] 41.69\n",
      "\n",
      "[65epoch Test] [loss] 0.45861 [acc] 78.58 [precision] 65.92 [recall] 14.30 [f1score] 23.50\n",
      "66epoch 64256/67016, [Acc] 79.48 [Loss] 0.43420\n",
      "[66epoch Train] [loss] 0.43474 [acc] 79.44 [precision] 59.87 [recall] 32.24 [f1score] 41.91\n",
      "\n",
      "[66epoch Test] [loss] 0.44050 [acc] 79.17 [precision] 58.97 [recall] 31.15 [f1score] 40.76\n",
      "67epoch 64256/67016, [Acc] 79.66 [Loss] 0.43337\n",
      "[67epoch Train] [loss] 0.43390 [acc] 79.62 [precision] 60.48 [recall] 32.91 [f1score] 42.63\n",
      "\n",
      "[67epoch Test] [loss] 0.44029 [acc] 79.32 [precision] 59.01 [recall] 33.13 [f1score] 42.44\n",
      "68epoch 64256/67016, [Acc] 79.54 [Loss] 0.43418\n",
      "[68epoch Train] [loss] 0.43436 [acc] 79.54 [precision] 60.07 [recall] 33.10 [f1score] 42.68\n",
      "\n",
      "[68epoch Test] [loss] 0.44079 [acc] 79.16 [precision] 57.59 [recall] 35.74 [f1score] 44.11\n",
      "69epoch 64256/67016, [Acc] 79.58 [Loss] 0.43484\n",
      "[69epoch Train] [loss] 0.43470 [acc] 79.58 [precision] 60.06 [recall] 33.64 [f1score] 43.13\n",
      "\n",
      "[69epoch Test] [loss] 0.44068 [acc] 79.25 [precision] 59.10 [recall] 31.83 [f1score] 41.38\n",
      "70epoch 64256/67016, [Acc] 79.66 [Loss] 0.43386\n",
      "[70epoch Train] [loss] 0.43431 [acc] 79.63 [precision] 60.14 [recall] 34.03 [f1score] 43.47\n",
      "\n",
      "[70epoch Test] [loss] 0.44224 [acc] 79.15 [precision] 63.32 [recall] 22.33 [f1score] 33.02\n",
      "71epoch 64256/67016, [Acc] 79.65 [Loss] 0.43429\n",
      "[71epoch Train] [loss] 0.43485 [acc] 79.66 [precision] 60.10 [recall] 34.47 [f1score] 43.81\n",
      "\n",
      "[71epoch Test] [loss] 0.44503 [acc] 79.16 [precision] 58.17 [recall] 33.52 [f1score] 42.53\n",
      "72epoch 64256/67016, [Acc] 79.67 [Loss] 0.43482\n",
      "[72epoch Train] [loss] 0.43516 [acc] 79.64 [precision] 60.50 [recall] 33.23 [f1score] 42.90\n",
      "\n",
      "[72epoch Test] [loss] 0.44189 [acc] 79.38 [precision] 61.67 [recall] 27.45 [f1score] 37.99\n",
      "73epoch 64256/67016, [Acc] 79.51 [Loss] 0.43518\n",
      "[73epoch Train] [loss] 0.43516 [acc] 79.52 [precision] 59.90 [recall] 33.33 [f1score] 42.82\n",
      "\n",
      "[73epoch Test] [loss] 0.44134 [acc] 79.19 [precision] 62.14 [recall] 24.49 [f1score] 35.14\n",
      "74epoch 64256/67016, [Acc] 79.55 [Loss] 0.43445\n",
      "[74epoch Train] [loss] 0.43371 [acc] 79.63 [precision] 61.09 [recall] 31.57 [f1score] 41.63\n",
      "\n",
      "[74epoch Test] [loss] 0.45588 [acc] 79.08 [precision] 63.00 [recall] 21.96 [f1score] 32.57\n",
      "75epoch 64256/67016, [Acc] 79.71 [Loss] 0.43396\n",
      "[75epoch Train] [loss] 0.43486 [acc] 79.63 [precision] 60.89 [recall] 32.07 [f1score] 42.01\n",
      "\n",
      "[75epoch Test] [loss] 0.44060 [acc] 79.01 [precision] 56.28 [recall] 39.38 [f1score] 46.34\n",
      "76epoch 64256/67016, [Acc] 79.54 [Loss] 0.43425\n",
      "[76epoch Train] [loss] 0.43526 [acc] 79.50 [precision] 60.29 [recall] 31.93 [f1score] 41.75\n",
      "\n",
      "[76epoch Test] [loss] 0.44455 [acc] 79.02 [precision] 58.43 [recall] 30.54 [f1score] 40.12\n",
      "77epoch 64256/67016, [Acc] 79.62 [Loss] 0.43417\n",
      "[77epoch Train] [loss] 0.43468 [acc] 79.59 [precision] 60.77 [recall] 31.83 [f1score] 41.78\n",
      "\n",
      "[77epoch Test] [loss] 0.44215 [acc] 79.31 [precision] 61.62 [recall] 26.71 [f1score] 37.27\n",
      "78epoch 64256/67016, [Acc] 79.67 [Loss] 0.43340\n",
      "[78epoch Train] [loss] 0.43415 [acc] 79.66 [precision] 60.55 [recall] 33.25 [f1score] 42.93\n",
      "\n",
      "[78epoch Test] [loss] 0.44316 [acc] 79.06 [precision] 60.41 [recall] 26.09 [f1score] 36.44\n",
      "79epoch 64256/67016, [Acc] 79.63 [Loss] 0.43442\n",
      "[79epoch Train] [loss] 0.43452 [acc] 79.59 [precision] 60.98 [recall] 31.43 [f1score] 41.48\n",
      "\n",
      "[79epoch Test] [loss] 0.44229 [acc] 78.94 [precision] 56.86 [recall] 35.18 [f1score] 43.46\n",
      "80epoch 64256/67016, [Acc] 79.70 [Loss] 0.43395\n",
      "[80epoch Train] [loss] 0.43488 [acc] 79.61 [precision] 60.41 [recall] 33.07 [f1score] 42.74\n",
      "\n",
      "[80epoch Test] [loss] 0.44870 [acc] 79.34 [precision] 62.05 [recall] 26.30 [f1score] 36.94\n",
      "81epoch 64256/67016, [Acc] 79.63 [Loss] 0.43501\n",
      "[81epoch Train] [loss] 0.43444 [acc] 79.64 [precision] 60.49 [recall] 33.17 [f1score] 42.85\n",
      "\n",
      "[81epoch Test] [loss] 0.44111 [acc] 79.34 [precision] 62.77 [recall] 25.06 [f1score] 35.82\n",
      "82epoch 64256/67016, [Acc] 79.60 [Loss] 0.43451\n",
      "[82epoch Train] [loss] 0.43440 [acc] 79.63 [precision] 61.19 [recall] 31.39 [f1score] 41.49\n",
      "\n",
      "[82epoch Test] [loss] 0.44174 [acc] 79.21 [precision] 60.56 [recall] 27.67 [f1score] 37.98\n",
      "83epoch 64256/67016, [Acc] 79.56 [Loss] 0.43462\n",
      "[83epoch Train] [loss] 0.43450 [acc] 79.57 [precision] 61.20 [recall] 30.62 [f1score] 40.82\n",
      "\n",
      "[83epoch Test] [loss] 0.44250 [acc] 79.19 [precision] 58.12 [recall] 34.20 [f1score] 43.06\n",
      "84epoch 64256/67016, [Acc] 79.54 [Loss] 0.43489\n",
      "[84epoch Train] [loss] 0.43454 [acc] 79.52 [precision] 59.99 [recall] 33.03 [f1score] 42.60\n",
      "\n",
      "[84epoch Test] [loss] 0.45046 [acc] 77.85 [precision] 72.16 [recall] 6.05 [f1score] 11.16\n",
      "85epoch 64256/67016, [Acc] 79.66 [Loss] 0.43355\n",
      "[85epoch Train] [loss] 0.43386 [acc] 79.66 [precision] 60.76 [recall] 32.81 [f1score] 42.61\n",
      "\n",
      "[85epoch Test] [loss] 0.44184 [acc] 78.94 [precision] 58.55 [recall] 28.99 [f1score] 38.78\n",
      "86epoch 64256/67016, [Acc] 79.53 [Loss] 0.43378\n",
      "[86epoch Train] [loss] 0.43486 [acc] 79.48 [precision] 60.18 [recall] 31.99 [f1score] 41.77\n",
      "\n",
      "[86epoch Test] [loss] 0.44323 [acc] 79.10 [precision] 58.38 [recall] 31.91 [f1score] 41.26\n",
      "87epoch 64256/67016, [Acc] 79.64 [Loss] 0.43344\n",
      "[87epoch Train] [loss] 0.43366 [acc] 79.61 [precision] 60.31 [recall] 33.31 [f1score] 42.92\n",
      "\n",
      "[87epoch Test] [loss] 0.44226 [acc] 79.10 [precision] 56.70 [recall] 38.75 [f1score] 46.04\n",
      "88epoch 64256/67016, [Acc] 79.49 [Loss] 0.43455\n",
      "[88epoch Train] [loss] 0.43487 [acc] 79.49 [precision] 59.74 [recall] 33.26 [f1score] 42.73\n",
      "\n",
      "[88epoch Test] [loss] 0.44192 [acc] 79.22 [precision] 58.90 [recall] 32.12 [f1score] 41.57\n",
      "89epoch 64256/67016, [Acc] 79.59 [Loss] 0.43433\n",
      "[89epoch Train] [loss] 0.43438 [acc] 79.63 [precision] 60.80 [recall] 32.30 [f1score] 42.18\n",
      "\n",
      "[89epoch Test] [loss] 0.44031 [acc] 79.18 [precision] 60.50 [recall] 27.41 [f1score] 37.73\n",
      "90epoch 64256/67016, [Acc] 79.50 [Loss] 0.43487\n",
      "[90epoch Train] [loss] 0.43422 [acc] 79.56 [precision] 60.57 [recall] 32.02 [f1score] 41.90\n",
      "\n",
      "[90epoch Test] [loss] 0.45014 [acc] 78.98 [precision] 56.67 [recall] 36.71 [f1score] 44.56\n",
      "91epoch 64256/67016, [Acc] 79.49 [Loss] 0.43449\n",
      "[91epoch Train] [loss] 0.43432 [acc] 79.52 [precision] 61.08 [recall] 30.30 [f1score] 40.51\n",
      "\n",
      "[91epoch Test] [loss] 0.44651 [acc] 79.30 [precision] 61.69 [recall] 26.44 [f1score] 37.01\n",
      "92epoch 64256/67016, [Acc] 79.59 [Loss] 0.43429\n",
      "[92epoch Train] [loss] 0.43410 [acc] 79.60 [precision] 60.86 [recall] 31.84 [f1score] 41.81\n",
      "\n",
      "[92epoch Test] [loss] 0.44119 [acc] 79.26 [precision] 59.54 [recall] 30.72 [f1score] 40.53\n",
      "93epoch 64256/67016, [Acc] 79.63 [Loss] 0.43399\n",
      "[93epoch Train] [loss] 0.43473 [acc] 79.59 [precision] 60.15 [recall] 33.50 [f1score] 43.03\n",
      "\n",
      "[93epoch Test] [loss] 0.44074 [acc] 79.13 [precision] 57.31 [recall] 36.38 [f1score] 44.51\n",
      "94epoch 64256/67016, [Acc] 79.60 [Loss] 0.43403\n",
      "[94epoch Train] [loss] 0.43467 [acc] 79.55 [precision] 60.80 [recall] 31.33 [f1score] 41.35\n",
      "\n",
      "[94epoch Test] [loss] 0.44044 [acc] 79.33 [precision] 61.33 [recall] 27.55 [f1score] 38.02\n",
      "95epoch 64256/67016, [Acc] 79.53 [Loss] 0.43498\n",
      "[95epoch Train] [loss] 0.43451 [acc] 79.59 [precision] 60.83 [recall] 31.75 [f1score] 41.72\n",
      "\n",
      "[95epoch Test] [loss] 0.44022 [acc] 79.34 [precision] 59.43 [recall] 32.12 [f1score] 41.70\n",
      "96epoch 64256/67016, [Acc] 79.56 [Loss] 0.43499\n",
      "[96epoch Train] [loss] 0.43452 [acc] 79.56 [precision] 60.60 [recall] 31.93 [f1score] 41.82\n",
      "\n",
      "[96epoch Test] [loss] 0.44818 [acc] 78.83 [precision] 55.77 [recall] 38.66 [f1score] 45.66\n",
      "97epoch 64256/67016, [Acc] 79.66 [Loss] 0.43443\n",
      "[97epoch Train] [loss] 0.43415 [acc] 79.66 [precision] 60.53 [recall] 33.37 [f1score] 43.02\n",
      "\n",
      "[97epoch Test] [loss] 0.45879 [acc] 76.99 [precision] 0.00 [recall] 0.00 [f1score] 0.00\n",
      "98epoch 64256/67016, [Acc] 79.66 [Loss] 0.43469\n",
      "[98epoch Train] [loss] 0.43477 [acc] 79.66 [precision] 61.17 [recall] 31.73 [f1score] 41.78\n",
      "\n",
      "[98epoch Test] [loss] 0.44108 [acc] 79.31 [precision] 59.38 [recall] 31.85 [f1score] 41.46\n",
      "99epoch 64256/67016, [Acc] 79.49 [Loss] 0.43467\n",
      "[99epoch Train] [loss] 0.43481 [acc] 79.52 [precision] 60.77 [recall] 31.06 [f1score] 41.11\n",
      "\n",
      "[99epoch Test] [loss] 0.44188 [acc] 79.02 [precision] 64.72 [recall] 19.38 [f1score] 29.82\n",
      "100epoch 64256/67016, [Acc] 79.73 [Loss] 0.43463\n",
      "[100epoch Train] [loss] 0.43445 [acc] 79.74 [precision] 61.20 [recall] 32.64 [f1score] 42.57\n",
      "\n",
      "[100epoch Test] [loss] 0.44202 [acc] 79.30 [precision] 62.36 [recall] 25.33 [f1score] 36.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "crime_model=nn.Sequential(nn.Linear(train_tensor_data.shape[1],5000),\n",
    "    nn.BatchNorm1d(5000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5000,1000),\n",
    "    nn.BatchNorm1d(1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000,500),\n",
    "    nn.BatchNorm1d(500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500,2),\n",
    "    # nn.Sigmoid()\n",
    "    )\n",
    "# criterion=torch.nn.BCELoss()\n",
    "crime_criterion=torch.nn.CrossEntropyLoss()\n",
    "crime_optimizer=torch.optim.Adam(crime_model.parameters(),lr=1e-2,weight_decay=1e-4)\n",
    "epochs=100\n",
    "\n",
    "def calc_score(outputs,targets,score_dict):\n",
    "  # this_correct=torch.eq(torch.max(outputs,dim=1)[1],targets).sum()\n",
    "  bsz=targets.size(0)\n",
    "  prediction=torch.max(outputs,dim=1)[1]\n",
    "  TP = (targets * prediction).sum().to(torch.float)\n",
    "  TN = ((1 - targets) * (1 - prediction)).sum().to(torch.float)\n",
    "  FP = ((1 - targets) * prediction).sum().to(torch.float)\n",
    "  FN = (targets * (1 - prediction)).sum().to(torch.float)\n",
    "  epsilon=1e-7\n",
    "  score_dict['total']+=bsz\n",
    "  score_dict['TP']+=TP.item()\n",
    "  score_dict['FP']+=FP.item()\n",
    "  score_dict['FN']+=FN.item()\n",
    "  score_dict['TN']+=TN.item()\n",
    "  score_dict['accuracy'] = ((score_dict['TP']+score_dict['TN'])/score_dict['total']*100.0)\n",
    "  score_dict['precision'] = (score_dict['TP']/(score_dict['TP']+score_dict['FP']+epsilon)*100.0)\n",
    "  score_dict['recall'] = (score_dict['TP']/(score_dict['TP']+score_dict['FN']+epsilon)*100.0)\n",
    "    \n",
    "  score_dict['f1score']=(2*score_dict['precision']*score_dict['recall'])/(score_dict['precision']+score_dict['recall']+epsilon)\n",
    "  \n",
    "  return score_dict\n",
    "\n",
    "def train(epoch,train_data_loader,model,optimizer,criterion):\n",
    "    model.train()\n",
    "    train_loss=0.0\n",
    "    score_dict={\n",
    "      'TP':0.0,\n",
    "      'TN':0.0,\n",
    "      'FP':0.0,\n",
    "      'FN':0.0,\n",
    "      'accuracy':0.0,\n",
    "      'total':0.0,\n",
    "      'precision':0.0,\n",
    "      'recall':0.0,\n",
    "      'f1score':0.0,\n",
    "      'loss':0.0,\n",
    "    }\n",
    "\n",
    "    for batch_idx, (data,targets) in enumerate(train_data_loader):\n",
    "        data,targets=data.cuda(),targets.cuda()\n",
    "        outputs=model(data)\n",
    "        loss=criterion(outputs,targets)#.view(-1,1))\n",
    "        score_dict=calc_score(outputs,targets,score_dict)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "        if batch_idx%50==1:\n",
    "            # print(outputs)\n",
    "            # print(torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).view(-1))\n",
    "            print('\\r{}epoch {}/{}, [Acc] {:.2f} [Loss] {:.5f}'.format(epoch,int(score_dict['total']),\n",
    "            len(train_data_loader.dataset),score_dict['accuracy'],train_loss/(batch_idx+1)),end='')\n",
    "    score_dict['loss']=train_loss/(batch_idx+1)\n",
    "    return score_dict\n",
    "\n",
    "def eval(epoch,test_data_loader,model,optimizer,criterion):\n",
    "  \n",
    "    score_dict={\n",
    "      'TP':0.0,\n",
    "      'TN':0.0,\n",
    "      'FP':0.0,\n",
    "      'FN':0.0,\n",
    "      'accuracy':0.0,\n",
    "      'total':0.0,\n",
    "      'precision':0.0,\n",
    "      'recall':0.0,\n",
    "      'f1score':0.0,\n",
    "    }\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss=0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for batch_idx,(data,targets) in enumerate(test_data_loader):\n",
    "          data,targets=data.cuda(),targets.cuda()\n",
    "          outputs=model(data)\n",
    "          score_dict=calc_score(outputs,targets,score_dict)\n",
    "          loss=criterion(outputs,targets)\n",
    "\n",
    "          eval_loss +=loss.item()\n",
    "    score_dict['loss']=eval_loss/(batch_idx+1)\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "crime_model.cuda()\n",
    "for epoch in range(1,epochs+1):\n",
    "    print('='*30)\n",
    "    score_dict=train(epoch,crime_train_data_loader,crime_model,crime_optimizer,crime_criterion)\n",
    "    print('\\n[{}epoch Train] [loss] {:.5f} [acc] {:.2f} [precision] {:.2f} [recall] {:.2f} [f1score] {:.2f}'.format(epoch,score_dict['loss'], score_dict['accuracy'],score_dict['precision'],score_dict['recall'],score_dict['f1score']))\n",
    "    score_dict=eval(epoch,crime_test_data_loader,crime_model,crime_optimizer,crime_criterion)\n",
    "    print('\\n[{}epoch Test] [loss] {:.5f} [acc] {:.2f} [precision] {:.2f} [recall] {:.2f} [f1score] {:.2f}'.format(epoch,score_dict['loss'], score_dict['accuracy'],score_dict['precision'],score_dict['recall'],score_dict['f1score']))\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_model=nn.Sequential(nn.Linear(train_tensor_data.shape[1],5000),\n",
    "    nn.BatchNorm1d(5000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5000,1000),\n",
    "    nn.BatchNorm1d(1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000,100),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,1)\n",
    ")\n",
    "priority_criterion=torch.nn.MSELoss()\n",
    "priority_optimizer=torch.optim.Adam(priority_model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'priority_model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-40023fd8dba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mpriority_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[0mscore_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpriority_train_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpriority_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpriority_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpriority_criterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'priority_model' is not defined"
     ]
    }
   ],
   "source": [
    "def train(epoch,train_data_loader,model,optimizer,criterion):\n",
    "  model.train()\n",
    "  total=0\n",
    "  correct=0.0\n",
    "  train_loss=0.0\n",
    "  for batch_idx, (data,targets) in enumerate(train_data_loader):\n",
    "      data,targets=data.cuda(),targets.cuda()\n",
    "      outputs=model(data)\n",
    "      loss=criterion(torch.clip(outputs,0,2),targets.view(-1,1))\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # correct+=torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).sum()\n",
    "      correct+=torch.eq(torch.round(outputs),targets.view(-1,1)).sum()\n",
    "      total += targets.size(0)\n",
    "      train_loss+=loss.item()\n",
    "      if batch_idx%50==1:\n",
    "          # print(outputs)\n",
    "          # print(torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).view(-1))\n",
    "          print('\\r{}epoch {}/{}, Accurcay: {:.2f} Loss:{:.5f}'.format(epoch,total,len(train_data_loader.dataset),correct/total*100.0,train_loss/(batch_idx+1)),end='')\n",
    "\n",
    "def eval(epoch,test_data_loader,model,optimizer,criterion):\n",
    "    model.eval()\n",
    "    eval_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0.0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx,(data,targets) in enumerate(test_data_loader):\n",
    "          data,targets=data.cuda(),targets.cuda()\n",
    "          outputs=model(data)\n",
    "          loss=criterion(outputs,targets.view(-1,1))\n",
    "          # correct+=torch.eq(torch.ge(outputs,0.5).float(),targets.view(-1,1)).sum()\n",
    "          correct+=torch.eq(torch.round(outputs),targets.view(-1,1)).sum()\n",
    "          total += targets.size(0)\n",
    "          eval_loss +=loss.item()\n",
    "\n",
    "    # print('\\n Eval: {} epoch, Accuracy: {:.2f}, Loss: {}'.format(epoch,correct/total*100.0,eval_loss/(batch_idx+1)))\n",
    "\n",
    "\n",
    "priority_model.cuda()\n",
    "for epoch in range(1,epochs+1):\n",
    "  score_dict=train(epoch,priority_train_data_loader,priority_model,priority_optimizer,priority_criterion)\n",
    "  print('[{}epoch Train]'.format(epoch),score_dict)\n",
    "  scoer_dict=eval(epoch,priority_test_data_loader,priority_model,priority_optimizer,priority_criterion)\n",
    "  print('[{}epoch Eval]'.format(epoch),score_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}